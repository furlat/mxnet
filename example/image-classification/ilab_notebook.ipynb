{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Simple Notebook for multitask learning over the ilab dataset, it makes use of the function ilab_iterator that has more than one label (4 tasks only 3 used: 0 categorization, 1 background id, vertical camera axis,horizontal camera axis) basically using task 0, 2,3 trains a multitask network able to express predictions over 10 categories + viewpoint coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "from common import find_mxnet, data, fit\n",
    "from common.util import download_file\n",
    "from ilab_iterator import ilab_iterator, Multi_ilab_iterator, Single_ilab_iterator\n",
    "import mxnet as mx\n",
    "import numpy\n",
    "\n",
    "# class AccuracyIlab(mx.metric.EvalMetric):\n",
    "#     \"\"\"Calculate accuracies of multi label\"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(Multi_Accuracy, self).__init__('multi-accuracy', num)\n",
    "\n",
    "#     def update(self, labels, preds):\n",
    "#         mx.metric.check_label_shapes(labels, preds)\n",
    "\n",
    "# #         if self.num != None:\n",
    "# #             assert len(labels) == self.num\n",
    "\n",
    "#         for i in range(len(labels)):\n",
    "#             pred_label = mx.nd.argmax_channel(preds[i]).asnumpy().astype('int32')\n",
    "#             label = labels[i].asnumpy().astype('int32')\n",
    "\n",
    "#             mx.metric.check_label_shapes(label, pred_label)\n",
    "\n",
    "#             if i == None:\n",
    "#                 self.sum_metric += (pred_label.flat == label.flat).sum()\n",
    "#                 self.num_inst += len(pred_label.flat)\n",
    "#             else:\n",
    "#                 self.sum_metric[i] += (pred_label.flat == label.flat).sum()\n",
    "#                 self.num_inst[i] += len(pred_label.flat)\n",
    "            \n",
    "class CrossEntropyIlab(mx.metric.EvalMetric):\n",
    "    \"\"\"Calculate Cross Entropy loss\"\"\"\n",
    "    def __init__(self,task=0):\n",
    "        super(CrossEntropyIlab, self).__init__('cross-entropy', task)\n",
    "        self.task = task\n",
    "\n",
    "    def update(self, labels, preds):\n",
    "        mx.metric.check_label_shapes(labels, preds)\n",
    "\n",
    "        for label, pred in zip(labels, preds):\n",
    "            label = label[self.task].asnumpy().astype('int32')\n",
    "            #label = label.asnumpy()\n",
    "            pred = pred.asnumpy()\n",
    "\n",
    "            label = label.ravel()\n",
    "            assert label.shape[0] == pred.shape[0]\n",
    "\n",
    "            prob = pred[numpy.arange(label.shape[0]), numpy.int64(label)]\n",
    "            self.sum_metric += (-numpy.log(prob)).sum()\n",
    "            self.num_inst += label.shape[0]\n",
    "            f.open('trainig_stats.txt')\n",
    "            f.write(self.sum_metric)\n",
    "            f.close()\n",
    "\n",
    "class Multi_Accuracy(mx.metric.EvalMetric):\n",
    "    \"\"\"Calculate accuracies of multi label\"\"\"\n",
    "\n",
    "    def __init__(self, num=None):\n",
    "        super(Multi_Accuracy, self).__init__('multi-accuracy', num)\n",
    "\n",
    "    def update(self, labels, preds):\n",
    "        mx.metric.check_label_shapes(labels, preds)\n",
    "\n",
    "        if self.num != None:\n",
    "            assert len(labels) == self.num\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            pred_label = mx.nd.argmax_channel(preds[i]).asnumpy().astype('int32')\n",
    "            label = labels[i].asnumpy().astype('int32')\n",
    "\n",
    "            mx.metric.check_label_shapes(label, pred_label)\n",
    "\n",
    "            if i == None:\n",
    "                self.sum_metric += (pred_label.flat == label.flat).sum()\n",
    "                self.num_inst += len(pred_label.flat)\n",
    "            else:\n",
    "                self.sum_metric[i] += (pred_label.flat == label.flat).sum()\n",
    "                self.num_inst[i] += len(pred_label.flat)\n",
    "                \n",
    "\n",
    "class Multi_Entropy(mx.metric.EvalMetric):\n",
    "    \"\"\"Calculate accuracies of multi label\"\"\"\n",
    "\n",
    "    def __init__(self, num=None):\n",
    "        super(Multi_Entropy, self).__init__('multi-entropy', num)\n",
    "\n",
    "    def update(self, labels, preds):\n",
    "        mx.metric.check_label_shapes(labels, preds)\n",
    "\n",
    "        if self.num != None:\n",
    "            assert len(labels) == self.num\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "               \n",
    "                pred = preds[i].asnumpy()\n",
    "                #pred = pred(pred_label)\n",
    "                #prb = pred.ravel()\n",
    "                label = labels[i].asnumpy().ravel()\n",
    "                assert label.shape[0] == pred.shape[0]\n",
    "\n",
    "                prob = pred[numpy.arange(label.shape[0]), numpy.int64(label)]\n",
    "                self.sum_metric[i] += (-numpy.log(prob)).sum()\n",
    "                self.num_inst[i] += label.shape[0] \n",
    "\n",
    "                \n",
    "class Multi_Entropy(mx.metric.EvalMetric):\n",
    "    \"\"\"Calculate accuracies of multi label\"\"\"\n",
    "\n",
    "    def __init__(self, num=None):\n",
    "        super(Multi_Entropy, self).__init__('multi-entropy', num)\n",
    "\n",
    "    def update(self, labels, preds):\n",
    "        mx.metric.check_label_shapes(labels, preds)\n",
    "\n",
    "        if self.num != None:\n",
    "            assert len(labels) == self.num\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "                #pred_label = mx.nd.argmax_channel(preds[i]).asnumpy()\n",
    "                #label = label.asnumpy()\n",
    "                pred = preds[i].asnumpy()\n",
    "                #pred = pred(pred_label)\n",
    "                #prb = pred.ravel()\n",
    "                label = labels[i].asnumpy().ravel()\n",
    "                assert label.shape[0] == pred.shape[0]\n",
    "               \n",
    "\n",
    "                prob = pred[numpy.arange(label.shape[0]), numpy.int64(label)]\n",
    "                self.sum_metric[i] += (-numpy.log(prob)).sum()\n",
    "                self.num_inst[i] += label.shape[0]\n",
    "                \n",
    "                \n",
    "class Cross_Entropy(mx.metric.EvalMetric):\n",
    "    \"\"\"Calculate accuracies of multi label\"\"\"\n",
    "\n",
    "    def __init__(self, num=None):\n",
    "        super(Cross_Entropy, self).__init__('cross-entropy',num)\n",
    "        #self.sum_metric=[]\n",
    "        #self.num = 3\n",
    "    def update(self, labels, preds):\n",
    "        mx.metric.check_label_shapes(labels, preds)\n",
    "        print len(labels) , self.num\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "                #pred_label = mx.nd.argmax_channel(preds[i]).asnumpy()\n",
    "                #label = label.asnumpy()\n",
    "                pred = preds[i].asnumpy()\n",
    "                #pred = pred(pred_label)\n",
    "                #prb = pred.ravel()\n",
    "                label = labels[i].asnumpy()\n",
    "                assert label.shape[0] == pred.shape[0]\n",
    "                for j in range(label.shape[0]):                   \n",
    "                    prob = pred[j,numpy.int64(label[i])]\n",
    "                    self.sum_metric[i] += (-numpy.log(prob)).sum()\n",
    "\n",
    "#                 prob = pred[numpy.arange(label.shape[0]), numpy.int64(label)]\n",
    "#                 self.sum_metric[i] += (-numpy.log(prob)).sum()\n",
    "                #self.num_inst[i] += label.shape[0]\n",
    "                \n",
    "                \n",
    "#         for i in range(len(labels)):\n",
    "#             #self.num = len(labels)\n",
    "#             label = labels[i].asnumpy()\n",
    "#             pred = preds[i].asnumpy()\n",
    "#             if len(labels) == 1:\n",
    "\n",
    "#                 for j in range(label.shape[0]):\n",
    "#                     prob = pred[j,numpy.int64(label[i])]\n",
    "\n",
    "#                     self.sum_metric += (-numpy.log(prob)).sum()\n",
    "#             else:\n",
    "#                 label = label.ravel()\n",
    "#                 prob = pred[numpy.arange(label.shape[0]), numpy.int64(label)]\n",
    "#                 self.sum_metric[i] += (-numpy.log(prob)).sum()    \n",
    "# if __name__ == '__main__':\n",
    "# download data\n",
    "\n",
    "# data setup\n",
    "# parse args\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_shape = '3,224,224'\n",
    "# load network\n",
    "from importlib import import_module\n",
    "net = import_module('symbols.resnet_md')\n",
    "#num_classes = [10,91,11,8]\n",
    "num_classes=[10,11,8]\n",
    "#num_classes=[10]\n",
    "batch_size = 64\n",
    "sym, data_names,label_names = net.get_vmt_symbol(num_classes, 50, image_shape, conv_workspace=256)\n",
    "mod = mx.mod.Module(sym, label_names=(label_names), context=[mx.gpu(0)])\n",
    "\n",
    "#mod = mx.mod.Module(sym, context=[mx.gpu(0)])\n",
    "\n",
    "train, val = ilab_iterator(batch_size=batch_size)\n",
    "train = Multi_ilab_iterator(train,subset=[0,2,3])\n",
    "val = Multi_ilab_iterator(val,subset=[0,2,3])\n",
    "# train = Single_ilab_iterator(train,labid=1)\n",
    "# val = Single_ilab_iterator(val,labid=1)\n",
    "\n",
    "model_prefix = '/home/ubuntu/results/ilab10_multi'\n",
    "#model_prefix = '/home/ubuntu/results/ilab_cat50'\n",
    "checkpoint = mx.callback.do_checkpoint(model_prefix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#lr_schedule it isimilar to the CIFAR100 schedule but half length of the steps\n",
    "schedule = [20000,30000,40000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mon = mx.monitor.Monitor(1,pattern='softmax2_output')\n",
    "#safety check to see whether all outputs are there\n",
    "sym.list_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually train the nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.fit(train,\n",
    "        eval_data=val,\n",
    "        eval_metric=Multi_Entropy(num=3),\n",
    "        batch_end_callback = mx.callback.log_train_metric(1),\n",
    "        epoch_end_callback=checkpoint,\n",
    "        optimizer_params={'learning_rate':0.1, 'momentum': 0.0,'wd':0.0004, 'lr_scheduler': mx.lr_scheduler.MultiFactorScheduler(step=schedule,factor=0.1) },\n",
    "        num_epoch=20)\n",
    "# train loading form nepoch\n",
    "# mod.fit(train, eval_data=val, epoch_end_callback=checkpoint, optimizer_params={'learning_rate':0.1, 'momentum': 0.9,'wd':0.0004}, num_epoch=300, arg_params=arg_params, aux_params=aux_params,\n",
    "#         begin_epoch=n_epoch_load)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get evaluation of multi accuracy and entropy on validation set at a specified epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = \\\n",
    "        mx.model.load_checkpoint(model_prefix, 5)\n",
    "mod.bind(data_shapes=train.provide_data,\n",
    "         label_shapes=val.provide_label)    \n",
    "mod.set_params(arg_params, aux_params)\n",
    "mod.score(val, Multi_Accuracy(num=3),num_batch=100)\n",
    "#mod.score(val, Multi_Entropy(num=3),num_batch=100)\n",
    "\n",
    "#mod.score(val, AccuracyIlab,num_batch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lab = [1,2,4,5,6]\n",
    "merge = 1\n",
    "rep = {1: [0]} #[1,2]\n",
    "i for merge in lab for i in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelid=[1]\n",
    "for i in range(len(labelid)):\n",
    "    print 'prot'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "mod.eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod._exec.eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=train.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.provide_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
