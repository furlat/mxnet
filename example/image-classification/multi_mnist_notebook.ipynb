{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "from common import find_mxnet, fit\n",
    "from common.util import download_file\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import gzip, struct\n",
    "from mxnet import profiler\n",
    "from time import time\n",
    "\n",
    "def read_data(label, image):\n",
    "    \"\"\"\n",
    "    download and read data into numpy\n",
    "    \"\"\"\n",
    "    base_url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    with gzip.open(download_file(base_url+label, os.path.join('data',label))) as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        label = np.fromstring(flbl.read(), dtype=np.int8)\n",
    "    with gzip.open(download_file(base_url+image, os.path.join('data',image)), 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n",
    "    return (label, image)\n",
    "\n",
    "\n",
    "def to4d(img):\n",
    "    \"\"\"\n",
    "    reshape to 4D arrays\n",
    "    \"\"\"\n",
    "    return img.reshape(img.shape[0], 1, 28, 28).astype(np.float32)/255\n",
    "\n",
    "def get_mnist_iter(batch_size):\n",
    "    \"\"\"\n",
    "    create data iterator with NDArrayIter\n",
    "    \"\"\"\n",
    "    (train_lbl, train_img) = read_data(\n",
    "            'train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz')\n",
    "    (val_lbl, val_img) = read_data(\n",
    "            't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz')\n",
    "    train = mx.io.NDArrayIter(\n",
    "        to4d(train_img), train_lbl, batch_size, shuffle=True)\n",
    "    val = mx.io.NDArrayIter(\n",
    "        to4d(val_img), val_lbl, batch_size)\n",
    "    return (train, val)\n",
    "\n",
    "class random_mnist_iterator(mx.io.DataIter):\n",
    "    '''random task ilab iterator'''\n",
    "    #requires bucketing module, only constraint should be that symgen in the bucketing module must give a single output with name softmax[bucketing_key+1]\n",
    "    def __init__(self, data_iter):\n",
    "        super(random_mnist_iterator, self).__init__()\n",
    "        self.data_iter = data_iter\n",
    "        self.batch_size = self.data_iter.batch_size\n",
    "\n",
    "    @property\n",
    "    def provide_data(self):\n",
    "        return self.data_iter.provide_data\n",
    "\n",
    "    @property\n",
    "    def provide_label(self):\n",
    "        provide_label = self.data_iter.provide_label\n",
    "        label_names=[]\n",
    "        batch_size=[]\n",
    "        for i in range(2):\n",
    "            label_names.append('softmax%d_label'%(i+1))\n",
    "            batch_size.append((self.batch_size,))\n",
    "            label_names=['softmax_label']\n",
    "        return zip(label_names,batch_size)  \n",
    "           \n",
    "         #provide_label must have an output like this       \n",
    "        #return [('softmax1_label', (self.batch_size,)), \\\n",
    "         #       ('softmax2_label', (self.batch_size,)), \\\n",
    "                #('softmax4_label', (self.batch_size,)), \\\n",
    "                #('softmax3_label', (self.batch_size,))]\n",
    "\n",
    "    def hard_reset(self):\n",
    "        self.data_iter.hard_reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.data_iter.reset()\n",
    "\n",
    "    def next(self):\n",
    "        batch = self.data_iter.next()\n",
    "        bucket_key = np.random.randint(0,2)\n",
    "        bucket_key = 0\n",
    "        #print bucket_key\n",
    "        labelnp=[]\n",
    "        # prepare all the labels\n",
    "        #print len(batch.label)\n",
    "        ##print batch.label[0].asnumpy().shape\n",
    "        #print batch.label[0].asnumpy()\n",
    "        #for lab in batch.label[0].asnumpy():\n",
    "        #    labelnp.append(mx.nd.array(lab))\n",
    "        # take the subset, in this case the single label_id \n",
    "        coarse_lab = batch.label[0].asnumpy()>4\n",
    "        c_lab = [mx.nd.array(1*coarse_lab)]\n",
    "        #print c_lab\n",
    "        #print 1*coarse_lab\n",
    "        f_lab = [batch.label[0]]\n",
    "        if bucket_key == 0:\n",
    "            all_label = f_lab\n",
    "        elif bucket_key == 1:\n",
    "            all_label = c_lab\n",
    "            \n",
    "        \n",
    "        #print all_label[0].asnumpy()\n",
    "        # generates the provide label adequate to the current label\n",
    "        label_names=[]\n",
    "        batch_size=[]\n",
    "        for bucket in [bucket_key]:\n",
    "            label_names.append('softmax%d_label'%(bucket+1))\n",
    "            batch_size.append((self.batch_size,))\n",
    "        label_names=['softmax_label']\n",
    "        #print zip(label_names,batch_size)\n",
    "        return mx.io.DataBatch(data=batch.data, label=all_label, \\\n",
    "                   pad=batch.pad, index=batch.index, bucket_key=bucket_key, provide_data=self.data_iter.provide_data,  provide_label=zip(label_names,batch_size)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_symbol(num_classes=10,):\n",
    "    data = mx.symbol.Variable('data')\n",
    "   \n",
    "    # first conv\n",
    "    conv1 = mx.symbol.Convolution(data=data, kernel=(5,5), num_filter=20)\n",
    "    tanh1 = mx.symbol.Activation(data=conv1, act_type=\"relu\")\n",
    "    pool1 = mx.symbol.Pooling(data=tanh1, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    # second conv\n",
    "    conv2 = mx.symbol.Convolution(data=pool1, kernel=(5,5), num_filter=50)\n",
    "    tanh2 = mx.symbol.Activation(data=conv2, act_type=\"relu\")\n",
    "    pool2 = mx.symbol.Pooling(data=tanh2, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    # first fullc\n",
    "    flatten = mx.symbol.Flatten(data=pool2)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "    tanh3 = mx.symbol.Activation(data=fc1, act_type=\"relu\")\n",
    "    # second fullc\n",
    "    fc2 = mx.symbol.FullyConnected(data=tanh3, num_hidden=num_classes)\n",
    "    # loss\n",
    "    lenet = mx.symbol.SoftmaxOutput(data=fc2, name='softmax')\n",
    "    return lenet\n",
    "\n",
    "def get_simple_symbol(num_classes=10,prefix=1):\n",
    "    data = mx.symbol.Variable('data')\n",
    "    data_name = ['data']\n",
    "    # first conv\n",
    "    conv1 = mx.symbol.Convolution(data=data, kernel=(5,5), num_filter=20,name='conv1')\n",
    "    tanh1 = mx.symbol.Activation(data=conv1, act_type=\"relu\")\n",
    "    pool1 = mx.symbol.Pooling(data=tanh1, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    # second conv\n",
    "    conv2 = mx.symbol.Convolution(data=pool1, kernel=(5,5), num_filter=50,name='conv2%d' %prefix)\n",
    "    tanh2 = mx.symbol.Activation(data=conv2, act_type=\"relu\",name='relu%d' %prefix)\n",
    "    pool2 = mx.symbol.Pooling(data=tanh2, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    # first fullc\n",
    "    flatten = mx.symbol.Flatten(data=pool2)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500,name='fc1%d' %prefix)\n",
    "    tanh3 = mx.symbol.Activation(data=fc1, act_type=\"relu\")\n",
    "    if prefix == 1:\n",
    "    # second fullc\n",
    "        fc2 = mx.symbol.FullyConnected(data=tanh3, num_hidden=num_classes,name='fc2%d' %prefix)\n",
    "    elif prefix == 2:\n",
    "        fc2 = mx.symbol.FullyConnected(data=tanh3, num_hidden=2,name='fc2%d' %prefix)\n",
    "    # loss\n",
    "    #lenet = mx.symbol.SoftmaxOutput(data=fc2, name='softmax%d'%prefix)\n",
    "    lenet = mx.symbol.SoftmaxOutput(data=fc2, name='softmax')\n",
    "\n",
    "    label_name = ['softmax_label']\n",
    "\n",
    "    #label_name = ['softmax%d_label'%prefix]\n",
    "            \n",
    "    return lenet,data_name, label_name\n",
    "\n",
    "def get_gated_simple_symbol(num_classes=10,prefix=1):\n",
    "    data = mx.symbol.Variable('data')\n",
    "    data_name = ['data']\n",
    "    # first conv\n",
    "    conv1 = mx.symbol.Convolution(data=data, kernel=(5,5), num_filter=20,name='conv1')\n",
    "    tanh1 = mx.symbol.Activation(data=conv1, act_type=\"relu\")\n",
    "    pool1 = mx.symbol.Pooling(data=tanh1, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    # second conv\n",
    "    conv2 = mx.symbol.Convolution(data=pool1, kernel=(5,5), num_filter=50,name='conv2%d' %prefix)\n",
    "    tanh2 = mx.symbol.Activation(data=conv2, act_type=\"relu\",name='relu%d' %prefix)\n",
    "    pool2 = mx.symbol.Pooling(data=tanh2, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    # first fullc\n",
    "    flatten = mx.symbol.Flatten(data=pool2)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500,name='fc1%d' %prefix)\n",
    "    gate = mx.sym.Variable('gate',init=mx.initializer.One(),shape=(1,),dtype='float32')\n",
    "    fc1_gated = mx.sym.broadcast_mul(gate,fc1)\n",
    "    tanh3 = mx.symbol.Activation(data=fc1_gated, act_type=\"relu\")\n",
    "    if prefix == 1:\n",
    "    # second fullc\n",
    "        fc2 = mx.symbol.FullyConnected(data=tanh3, num_hidden=num_classes,name='fc2%d' %prefix)\n",
    "    elif prefix == 2:\n",
    "        fc2 = mx.symbol.FullyConnected(data=tanh3, num_hidden=2,name='fc2%d' %prefix)\n",
    "    # loss\n",
    "    lenet = mx.symbol.SoftmaxOutput(data=fc2, name='softmax')\n",
    "    label_name = ['softmax_label']\n",
    "            \n",
    "    return lenet,data_name, label_name\n",
    "\n",
    "def get_big_symbol(num_classes=10):\n",
    "    data = mx.symbol.Variable('data')\n",
    "    data_name = ['data']  \n",
    "    # first conv\n",
    "    conv1 = mx.symbol.Convolution(data=data, kernel=(5,5), num_filter=20,name='conv1')\n",
    "    tanh1 = mx.symbol.Activation(data=conv1, act_type=\"relu\")\n",
    "    pool1 = mx.symbol.Pooling(data=tanh1, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    # second conv\n",
    "    conv2_1 = mx.symbol.Convolution(data=pool1, kernel=(5,5), num_filter=50,name='conv21')\n",
    "    tanh2_1 = mx.symbol.Activation(data=conv2_1, act_type=\"relu\",name='relu1' )\n",
    "    pool2_1 = mx.symbol.Pooling(data=tanh2_1, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    \n",
    "    conv2_2 = mx.symbol.Convolution(data=pool1, kernel=(5,5), num_filter=50,name='conv22' )\n",
    "    tanh2_2 = mx.symbol.Activation(data=conv2_2, act_type=\"relu\",name='relu2')\n",
    "    pool2_2 = mx.symbol.Pooling(data=tanh2_2, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    # first fullc\n",
    "    flatten_1 = mx.symbol.Flatten(data=pool2_1)\n",
    "    fc1_1 = mx.symbol.FullyConnected(data=flatten_1, num_hidden=500,name='fc11')\n",
    "    \n",
    "    tanh3_1 = mx.symbol.Activation(data=fc1_1, act_type=\"relu\")\n",
    "    \n",
    "    flatten_2 = mx.symbol.Flatten(data=pool2_2)\n",
    "    fc1_2 = mx.symbol.FullyConnected(data=flatten_2, num_hidden=500,name='fc12' )\n",
    "    tanh3_2 = mx.symbol.Activation(data=fc1_2, act_type=\"relu\")\n",
    "    # second fullc\n",
    "    fc2_1 = mx.symbol.FullyConnected(data=tanh3_1, num_hidden=num_classes,name='fc21' )\n",
    "    fc2_2 = mx.symbol.FullyConnected(data=tanh3_2, num_hidden=2,name='fc22' )\n",
    "    # loss\n",
    "    sym_1 = mx.symbol.SoftmaxOutput(data=fc2_1, name='softmax1')\n",
    "    sym_2 = mx.symbol.SoftmaxOutput(data=fc2_2, name='softmax2')\n",
    "    label_name=['softmax1_label','softmax2_label']\n",
    "    \n",
    "    return mx.sym.Group([sym_1,sym_2]),data_name, label_name\n",
    "\n",
    "def sym_gen(key):\n",
    "    if key == 0:\n",
    "        sym, data_names,label_names = get_simple_symbol(num_classes=10,prefix=1)\n",
    "    elif key == 1:    \n",
    "        sym ,data_names,label_names= get_simple_symbol(num_classes=10,prefix=2)\n",
    "    elif key == 2:\n",
    "        sym,data_names,label_names = get_big_symbol(num_classes=10)\n",
    "        \n",
    "    return sym,data_names,label_names  \n",
    "\n",
    "def gated_sym_gen(key):\n",
    "    if key == 0:\n",
    "        sym, data_names,label_names = get_simple_symbol(num_classes=10,prefix=1)\n",
    "    elif key == 1:    \n",
    "        sym ,data_names,label_names= get_gated_simple_symbol(num_classes=10,prefix=1)\n",
    "    elif key == 2:\n",
    "        sym,data_names,label_names = get_big_symbol(num_classes=10)\n",
    "        \n",
    "    return sym,data_names,label_names    \n",
    "batch_size = 10000\n",
    "train, val = get_mnist_iter(batch_size)\n",
    "train = random_mnist_iterator(train)\n",
    "val = random_mnist_iterator(val)\n",
    "\n",
    "schedule = [20000,30000,40000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sym,data,labels=gated_sym_gen(1)\n",
    "#mx.viz.plot_network(sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sym, data_names,label_names = get_simple_symbol(num_classes=10,prefix=1)\n",
    "# sym,data_names,label_names = get_big_symbol(num_classes=10)\n",
    "# sym.list_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['softmax_label']\n"
     ]
    }
   ],
   "source": [
    "#lel=train.provide_label[0][0]\n",
    "mod = mx.mod.Module(sym, label_names=labels, context=[mx.gpu(0)])\n",
    "#mod = mx.mod.BucketingModule(sym_gen,default_bucket_key=2, context=[mx.gpu(0)])\n",
    "print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward time is 0.000754833221436\n",
      "backward time is 0.000375986099243\n",
      "update time is 0.00330781936646\n",
      "forward time is 0.000627040863037\n",
      "backward time is 4.2200088501e-05\n",
      "update time is 0.00121402740479\n",
      "forward time is 0.000645160675049\n",
      "backward time is 0.000134944915771\n",
      "update time is 0.00147390365601\n",
      "forward time is 0.000670194625854\n",
      "backward time is 0.000105142593384\n",
      "update time is 0.0014660358429\n",
      "forward time is 0.00062894821167\n",
      "backward time is 0.000285863876343\n",
      "update time is 0.00125694274902\n"
     ]
    }
   ],
   "source": [
    "iterations = 5\n",
    "#profiler.profiler_set_config(mode='symbolic', filename='profile_output.json')\n",
    "# profiler.profiler_set_state('run')\n",
    "optimizer='sgd'\n",
    "kvstore='local'\n",
    "optimizer_params={'learning_rate':0.1, 'momentum': 0.9,'wd':0.0000, 'lr_scheduler': mx.lr_scheduler.MultiFactorScheduler(step=schedule,factor=0.1) }\n",
    "# mod.bind()\n",
    "mod.bind(data_shapes=train.provide_data,\n",
    "              label_shapes=train.provide_label)\n",
    "mod.init_params()\n",
    "mod.init_optimizer(kvstore=kvstore, optimizer=optimizer,\n",
    "                            optimizer_params=optimizer_params)\n",
    "\n",
    "#profiler.profiler_set_state('run')\n",
    "\n",
    "# real run    \n",
    "for i in range(iterations):\n",
    "    batch=train.next()\n",
    "    start_for = time()\n",
    "    mod.forward(batch, is_train=True)\n",
    "    print 'forward time is'+' '+str(time()-start_for)\n",
    "    start_back= time()\n",
    "    mod.backward()\n",
    "    print 'backward time is'+' '+str(time()-start_back)\n",
    "    start_upd = time()\n",
    "    mod.update()\n",
    "    print 'update time is'+' '+str(time()-start_upd)\n",
    "    for output in mod.get_outputs(merge_multi_context=False)[0]:\n",
    "        output.wait_to_read()\n",
    "#profiler.profiler_set_state('stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-e1129b9874fd>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-e1129b9874fd>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    forward time is 0.000964879989624\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#no scalar\n",
    "forward time is 0.000964879989624\n",
    "backward time is 0.000248193740845\n",
    "update time is 0.00177907943726\n",
    "forward time is 0.000608921051025\n",
    "backward time is 0.0024790763855\n",
    "update time is 0.000823020935059\n",
    "forward time is 0.000785827636719\n",
    "backward time is 0.000428915023804\n",
    "update time is 0.00115990638733\n",
    "forward time is 0.000653982162476\n",
    "backward time is 0.000313997268677\n",
    "update time is 0.00117301940918\n",
    "forward time is 0.000581026077271\n",
    "backward time is 0.000270128250122\n",
    "update time is 0.00115299224854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already binded, ignoring bind()\n",
      "/home/ubuntu/mxnet/python/mxnet/module/base_module.py:446: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Train-accuracy=0.114600\n",
      "INFO:root:Epoch[0] Time cost=0.139\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.113500\n",
      "INFO:root:Epoch[1] Batch [0]\tSpeed: 11450.18 samples/sec\tTrain-accuracy=0.110600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving logfiles0  at None-metric-log-0.txt\n"
     ]
    }
   ],
   "source": [
    "mod.fit(train,\n",
    "        eval_data=val,\n",
    "        eval_metric=[mx.metric.Accuracy()],\n",
    "        batch_end_callback = [mx.callback.Speedometer(1,batch_size)],\n",
    "        allow_missing=False,\n",
    "        optimizer_params={'learning_rate':0.1, 'momentum': 0.9,'wd':0.0000, 'lr_scheduler': mx.lr_scheduler.MultiFactorScheduler(step=schedule,factor=0.1) },\n",
    "        num_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod._buckets[2].get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod._buckets[1].eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = train.next()\n",
    "a.provide_data[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.provide_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
