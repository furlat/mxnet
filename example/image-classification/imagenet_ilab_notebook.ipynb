{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "from common import find_mxnet, data, fit\n",
    "from common.util import download_file\n",
    "from ilab_iterator import ilab_iterator, Multi_ilab_iterator, Single_ilab_iterator, random_task_iterator\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Cross_Entropy(mx.metric.EvalMetric):\n",
    "    \"\"\"Calculate accuracies of multi label\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Cross_Entropy, self).__init__('cross-entropy')\n",
    "    def update(self, labels, preds):\n",
    "        mx.metric.check_label_shapes(labels, preds)\n",
    "        label = labels[0].asnumpy()\n",
    "        pred = preds[0].asnumpy()\n",
    "        for i in range(label.shape[0]):\n",
    "            prob = pred[i,numpy.int64(label[i])]\n",
    "            if len(labels) == 1:\n",
    "                self.sum_metric += (-numpy.log(prob)).sum()\n",
    "        self.num_inst += label.shape[0]\n",
    "        \n",
    "class Multi_Entropy(mx.metric.EvalMetric):\n",
    "    \"\"\"Calculate accuracies of multi label\"\"\"\n",
    "\n",
    "    def __init__(self, num=None):\n",
    "        super(Multi_Entropy, self).__init__('multi-entropy', num)\n",
    "\n",
    "    def update(self, labels, preds):\n",
    "        mx.metric.check_label_shapes(labels, preds)\n",
    "\n",
    "        if self.num != None:\n",
    "            assert len(labels) == self.num\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "                #pred_label = mx.nd.argmax_channel(preds[i]).asnumpy()\n",
    "                #label = label.asnumpy()\n",
    "                pred = preds[i].asnumpy()\n",
    "                #pred = pred(pred_label)\n",
    "                #prb = pred.ravel()\n",
    "                label = labels[i].asnumpy().ravel()\n",
    "                assert label.shape[0] == pred.shape[0]\n",
    "               \n",
    "\n",
    "                prob = pred[numpy.arange(label.shape[0]), numpy.int64(label)]\n",
    "                self.sum_metric[i] += (-numpy.log(prob)).sum()\n",
    "                self.num_inst[i] += label.shape[0]        \n",
    "        \n",
    "# class Cross_Entropy(mx.metric.EvalMetric):\n",
    "#     \"\"\"Calculate accuracies of multi label\"\"\"\n",
    "\n",
    "#     def __init__(self, num=None):\n",
    "#         super(Cross_Entropy, self).__init__('cross-entropy',num)\n",
    "#         #self.sum_metric=[]\n",
    "#         #self.num = 3\n",
    "#         self.eps =  numpy.finfo(float).eps\n",
    "#     def update(self, labels, preds):\n",
    "#         mx.metric.check_label_shapes(labels, preds)\n",
    "#         #print len(labels) , self.num\n",
    "        \n",
    "#         for i in range(len(labels)):\n",
    "#                 pred = preds[i].asnumpy()\n",
    "#                 label = labels[i].asnumpy()\n",
    "#                 assert label.shape[0] == pred.shape[0]\n",
    "#                 if len(labels)==1:\n",
    "#                     #print 'long one'\n",
    "#                     for j in range(pred.shape[0]):                   \n",
    "#                         prob = pred[j,numpy.int64(label[0])]\n",
    "#                         self.sum_metric[0] += (-numpy.log(prob+self.eps  )).sum()\n",
    "#                     self.num_inst[0] += label.shape[0]   \n",
    "#                 else:\n",
    "#                     #print 'not long as one'\n",
    "#                     for j in range(pred.shape[0]):                   \n",
    "#                         prob = pred[j,numpy.int64(label[i])]\n",
    "#                         #print label[i]\n",
    "#                         self.sum_metric[i+1] += (-numpy.log(prob+ self.eps)).sum()\n",
    "#                     self.num_inst[i+1] += label.shape[0]     \n",
    "\n",
    "                \n",
    "# class Cross_Entropy(mx.metric.EvalMetric):\n",
    "#     \"\"\"Calculate accuracies of multi label\"\"\"\n",
    "\n",
    "#     def __init__(self, num=None):\n",
    "#         super(Cross_Entropy, self).__init__('cross-entropy',num)\n",
    "#         #self.sum_metric=[]\n",
    "#         #self.num = 3\n",
    "#     def update(self, labels, preds):\n",
    "#         mx.metric.check_label_shapes(labels, preds)\n",
    "#         #print len(labels) , self.num\n",
    "        \n",
    "#         for i in range(len(labels)):\n",
    "#                 pred = preds[i].asnumpy()\n",
    "#                 label = labels[i].asnumpy()\n",
    "#                 assert label.shape[0] == pred.shape[0]\n",
    "#                 if len(labels)==1:\n",
    "#                     for j in range(label.shape[0]):                   \n",
    "#                         prob = pred[j,numpy.int64(label[0])]\n",
    "#                         self.sum_metric[0] += (-numpy.log(prob)).sum()\n",
    "#                     self.num_inst[0] += label.shape[0]    \n",
    "#                 else:\n",
    "#                     for j in range(label.shape[0]):                   \n",
    "#                         prob = pred[j,numpy.int64(label[i])]\n",
    "#                         self.sum_metric[i] += (-numpy.log(prob)).sum()\n",
    "#                     self.num_inst[i] += label.shape[0]    \n",
    "\n",
    "                    \n",
    "class multi_iter_iterator(mx.io.DataIter):\n",
    "    '''random task ilab iterator'''\n",
    "    #requires bucketing module, only constraint should be that symgen in the bucketing module must give a single output with name softmax[bucketing_key+1]\n",
    "    def __init__(self, data_iter_list,iter_active,maxbatch):\n",
    "        super(multi_iter_iterator, self).__init__()\n",
    "        self.data_iter_list = data_iter_list\n",
    "        self.batch_size = self.data_iter_list[0].batch_size\n",
    "        self.iter_active = iter_active \n",
    "        self.iter_id=0\n",
    "        self.counter = 0\n",
    "        for i,iterator in enumerate(data_iter_list):\n",
    "            data_iter_list[i] = mx.io.ResizeIter(iterator,maxbatch,reset_internal=False)\n",
    "        \n",
    "        assert len(iter_active)==len(data_iter_list)\n",
    "        #self.num_classes = num_cl\n",
    "\n",
    "    @property\n",
    "    def provide_data(self):\n",
    "        return self.data_iter_list[0].provide_data\n",
    "\n",
    "    @property\n",
    "    def provide_label(self):\n",
    "        return self.data_iter_list[0].provide_label\n",
    "\n",
    "    def hard_reset(self):\n",
    "        for data_iter in self.data_iter_list:\n",
    "            data_iter.hard_reset()\n",
    "\n",
    "    def reset(self):\n",
    "        for data_iter in self.data_iter_list:\n",
    "            data_iter.reset()\n",
    "\n",
    "    def next(self):\n",
    "        #first a random dataset is selected\n",
    "        #iter_id = np.random.randint(0,len(self.data_iter_list))\n",
    "        iter_id = self.iter_id\n",
    "        #print iter_id\n",
    "        #change iter at next timestep\n",
    "        if iter_id == 0:\n",
    "            if self.counter <  10:\n",
    "                self.iter_id = 0\n",
    "            else:\n",
    "                if self.counter == 100:\n",
    "                    print 'inizio Ilab'\n",
    "                \n",
    "                self.iter_id = 1\n",
    "            \n",
    "        elif iter_id == 1:\n",
    "            self.iter_id = 0\n",
    "        self.counter += 1    \n",
    "        batch = self.data_iter_list[iter_id].next()\n",
    "        label_names = []\n",
    "        batch_size = []\n",
    "        for i,j in enumerate(self.iter_active[iter_id]):\n",
    "            if j==1:\n",
    "                label_names.append('softmax%d_label'%(i+1))\n",
    "                batch_size.append((self.batch_size,))\n",
    "\n",
    "        return mx.io.DataBatch(data=batch.data, label=batch.label, \\\n",
    "                   pad=batch.pad, index=batch.index, bucket_key=iter_id, provide_data=self.data_iter_list[iter_id].provide_data,  provide_label=zip(label_names,batch_size))                             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imagenet_iterator(data_dir,batch_size):\n",
    "    train = mx.io.ImageRecordIter(\n",
    "            path_imgrec         = os.path.join(data_dir, \"imagenet_small_train.rec\"),\n",
    "            label_width         = 1,\n",
    "            data_name           = 'data',\n",
    "            label_name          = 'softmax1_label',\n",
    "            data_shape          = (3, 224, 224),\n",
    "            batch_size          = batch_size,\n",
    "            pad                 = 0,\n",
    "            fill_value          = 127,  # only used when pad is valid\n",
    "            rand_crop           = True,\n",
    "            max_random_scale    = 1.0,  # 480 with imagnet, 32 with cifar10\n",
    "            min_random_scale    = 0.533,  # 256.0/480.0\n",
    "            max_aspect_ratio    =  0.25,\n",
    "            random_h            = 36,  # 0.4*90\n",
    "            random_s            = 50,  # 0.4*127\n",
    "            random_l            = 50,  # 0.4*127\n",
    "            max_rotate_angle    = 10,\n",
    "            max_shear_ratio     = 0.1,\n",
    "            rand_mirror         = True,\n",
    "            shuffle             = True)\n",
    "            #num_parts           = kv.num_workers,\n",
    "            #part_index          = kv.rank)\n",
    "    val = mx.io.ImageRecordIter(\n",
    "            path_imgrec         = os.path.join(data_dir, \"imagenet_small_val.rec\"),\n",
    "            label_width         = 1,\n",
    "            data_name           = 'data',\n",
    "            label_name          = 'softmax1_label',\n",
    "            batch_size          = batch_size,\n",
    "            data_shape          = (3, 224, 224),\n",
    "            rand_crop           = False,\n",
    "            rand_mirror         = False)\n",
    "            #num_parts           = kv.num_workers,\n",
    "            #part_index          = kv.rank)\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare the single_dataset iterators\n",
    "#ilab\n",
    "batch_size = 1280\n",
    "data_dir='/efs/datasets/users/furlat/imagenet'\n",
    "train_ilab, val_ilab = ilab_iterator(batch_size)\n",
    "train_ilab = Multi_ilab_iterator(train_ilab,subset=[0,2,3])\n",
    "#train_ilab2= mx.io.ResizeIter(train_ilab,1000,reset_internal=False)\n",
    "val_ilab = Multi_ilab_iterator(val_ilab,subset=[0,2,3])\n",
    "\n",
    "train_imag, val_imag = imagenet_iterator(data_dir,batch_size)\n",
    "train_multi = multi_iter_iterator([train_imag,train_ilab],[[1,0,0,0],[0,1,1,1]],1000)\n",
    "val_multi = multi_iter_iterator([val_imag,val_ilab],[[1,0,0,0],[0,1,1,1]],100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from importlib import import_module\n",
    "net = import_module('symbols.resnet_md')\n",
    "#batch_size = 16\n",
    "image_shape = '3,224,224'\n",
    "\n",
    "def sym_gen(bucket_key):\n",
    "    num_classes=[1000,10,11,8]\n",
    "    active = [[1,0,0,0],[0,1,1,1]]\n",
    "    rescale_grad=[1,0.5]\n",
    "    if bucket_key == 2:\n",
    "        return net.get_vmt_symbol(num_classes, 50, image_shape, conv_workspace=256)\n",
    "    else:\n",
    "        return net.get_mt_symbol(num_classes,active[bucket_key],rescale_grad[bucket_key], 50, image_shape, conv_workspace=256)\n",
    "\n",
    "ctx=[mx.gpu(0),mx.gpu(1),mx.gpu(2),mx.gpu(3),mx.gpu(4),mx.gpu(5),mx.gpu(6),mx.gpu(7),mx.gpu(8),mx.gpu(9),mx.gpu(10),mx.gpu(11),mx.gpu(12),mx.gpu(13),mx.gpu(14),mx.gpu(15)]\n",
    "mod = mx.mod.BucketingModule(sym_gen,default_bucket_key=2, context=ctx)\n",
    "\n",
    "#mod = mx.mod.BucketingModule(sym_gen,default_bucket_key=2, context=[mx.gpu(0)])\n",
    "\n",
    "\n",
    "model_prefix = '/home/ubuntu/results/imagenet_ilab'\n",
    "#model_prefix2load=/efs/datasets/users/furlat/imagenet/imagenet_r50-0013.params\n",
    "\n",
    "checkpoint = mx.callback.module_checkpoint(mod,model_prefix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#lr_schedule it isimilar to the CIFAR100 schedule but half length of the steps\n",
    "schedule = [20000,30000,40000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sym, arg_params, aux_params = \\\n",
    " #       mx.model.load_checkpoint(model_prefix, 36)\n",
    "#print arg_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mod._buckets[0].bind(data_shapes=train_imag.provide_data,\n",
    " #        label_shapes=val_imag.provide_label)    \n",
    "#mod._buckets[0].set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.fit(train_multi,\n",
    "        eval_data=val_multi,\n",
    "        eval_metric=[Cross_Entropy(),Multi_Entropy(num=3)],#(num=4),\n",
    "        batch_end_callback = mx.callback.log_train_metric(5),\n",
    "        epoch_end_callback=checkpoint,\n",
    "        allow_missing=False,\n",
    "        optimizer_params={'learning_rate':0.1, 'momentum': 0.9,'wd':0.0001, 'lr_scheduler': mx.lr_scheduler.MultiFactorScheduler(step=schedule,factor=0.1) },\n",
    "        num_epoch=20, log_prefix = model_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod._buckets[2].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eps = numpy.finfo(float).eps\n",
    "print eps + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loge = [[]]\n",
    "print loge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [[] for i in range(3)]\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x[1].append('mona')\n",
    "x[2].append('mona2')\n",
    "x[1].append('mona11')\n",
    "print x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meh=[('multi-entropy_0', 2.6418150588870049), ('multi-entropy_1', 2.5432480663061141), ('multi-entropy_2', 2.3565363720059396)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b= a[1] for a in meh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for nbatch, data_batch in enumerate(train_multi):\n",
    "len(train_multi)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
