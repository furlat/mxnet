{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "from common import find_mxnet, data, fit\n",
    "from common.util import download_file\n",
    "from ilab_iterator import ilab_iterator, Multi_ilab_iterator, Single_ilab_iterator, random_task_iterator\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import numpy\n",
    "from mxnet import nd\n",
    "\n",
    "\n",
    "class Cross_Entropy(mx.metric.EvalMetric):\n",
    "    \"\"\"Calculate accuracies of multi label\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Cross_Entropy, self).__init__('cross-entropy')\n",
    "    def update(self, labels, preds):\n",
    "        mx.metric.check_label_shapes(labels, preds)\n",
    "        label = labels[0].asnumpy()\n",
    "        pred = preds[0].asnumpy()\n",
    "        for i in range(label.shape[0]):\n",
    "            prob = pred[i,numpy.int64(label[i])]\n",
    "            if len(labels) == 1:\n",
    "                self.sum_metric += (-numpy.log(prob)).sum()\n",
    "        self.num_inst += label.shape[0]         \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sketches_iterator(data_dir,batch_size):\n",
    "    train = mx.io.ImageRecordIter(\n",
    "            path_imgrec         = os.path.join(data_dir, \"human_sketches_train.rec\"),\n",
    "            label_width         = 1,\n",
    "            data_name           = 'data',\n",
    "            label_name          = 'softmax1_label',\n",
    "            data_shape          = (3, 224, 224),\n",
    "            batch_size          = batch_size,\n",
    "            pad                 = 0,\n",
    "            fill_value          = 127,  # only used when pad is valid\n",
    "            rand_crop           = True,\n",
    "            max_random_scale    = 1.0,  # 480 with imagnet, 32 with cifar10\n",
    "            min_random_scale    = 1,  # 256.0/480.0\n",
    "            max_aspect_ratio    =  0.25,\n",
    "            random_h            = 36,  # 0.4*90\n",
    "            random_s            = 50,  # 0.4*127\n",
    "            random_l            = 50,  # 0.4*127\n",
    "            #max_rotate_angle    = 10,\n",
    "            #max_shear_ratio     = 0.1, #\n",
    "            rand_mirror         = True,\n",
    "            shuffle             = True)\n",
    "            #num_parts           = kv.num_workers,\n",
    "            #part_index          = kv.rank)\n",
    "    val = mx.io.ImageRecordIter(\n",
    "            path_imgrec         = os.path.join(data_dir, \"human_sketches_val.rec\"),\n",
    "            label_width         = 1,\n",
    "            data_name           = 'data',\n",
    "            label_name          = 'softmax1_label',\n",
    "            batch_size          = batch_size,\n",
    "            data_shape          = (3, 224, 224),\n",
    "            rand_crop           = False,\n",
    "            rand_mirror         = False)\n",
    "            #num_parts           = kv.num_workers,\n",
    "            #part_index          = kv.rank)\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare the single_dataset iterators\n",
    "#ilab\n",
    "batch_size = 256\n",
    "data_dir='/efs/datasets/users/furlat/human_sketches'\n",
    "#places\n",
    "train_sketches, val_sketches = sketches_iterator(data_dir,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from importlib import import_module\n",
    "net = import_module('symbols.resnet_md')\n",
    "image_shape = '3,224,224'\n",
    "label_names = [train_sketches.provide_label[0][0]]\n",
    "num_classes=[365]\n",
    "sym = net.get_vmt_symbol(num_classes, 50, image_shape, conv_workspace=256)  \n",
    "sym=sym[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctx=[mx.gpu(0),mx.gpu(1),mx.gpu(2),mx.gpu(3),mx.gpu(4),mx.gpu(5),mx.gpu(6),mx.gpu(7),mx.gpu(8),mx.gpu(9),mx.gpu(10),mx.gpu(11),mx.gpu(12),mx.gpu(13),mx.gpu(14),mx.gpu(15)]\n",
    "\n",
    "\n",
    "\n",
    "model_prefix = '/home/ubuntu/results/sketches-imagenet-init'\n",
    "imagenet_weights= '/efs/datasets/users/furlat/results_imagenet/imagenet_r50-lr05'\n",
    "\n",
    "\n",
    "#lr_schedule it isimilar to the CIFAR100 schedule but half length of the steps\n",
    "# schedule = [240000,480000,720000]\n",
    "# sym, arg_params, aux_params = \\\n",
    "#          mx.model.load_checkpoint(checkpoint, 4)\n",
    "\n",
    "# mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prefix = imagenet_weights\n",
    "#prefix = model_prefix\n",
    "epoch=120\n",
    "save_dict = nd.load('%s-%04d.params' % (prefix, epoch))\n",
    "\n",
    "arg_params_imag = {}\n",
    "aux_params_imag = {}\n",
    "for k, v in save_dict.items():\n",
    "    tp, name = k.split(':', 1)\n",
    "    if tp == 'arg':\n",
    "        arg_params_imag[name] = v\n",
    "    if tp == 'aux':\n",
    "        aux_params_imag[name] = v\n",
    "del arg_params_imag['fc1_bias']\n",
    "del arg_params_imag['fc1_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arg_params_imag.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(sym, label_names=label_names,fixed_param_names=None, context=ctx)\n",
    "#arg_params_imag.keys()\n",
    "checkpoint = mx.callback.module_checkpoint(mod,model_prefix)\n",
    "mod.bind(data_shapes=train_sketches.provide_data, label_shapes=val_sketches.provide_label)\n",
    "mod.init_params()\n",
    "# print mod.get_params()[0]['bn0_beta'].asnumpy()\n",
    "mod.set_params(arg_params_imag, aux_params_imag, allow_missing=True)\n",
    "# print mod.get_params()[0]['bn0_beta'].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.fit(train_sketches,\n",
    "        eval_data=val_sketches,\n",
    "        eval_metric=[Cross_Entropy()],\n",
    "        batch_end_callback = mx.callback.log_train_metric(5),\n",
    "        epoch_end_callback=checkpoint,\n",
    "        allow_missing=False,\n",
    "        begin_epoch=1,\n",
    "        log_prefix = model_prefix,\n",
    "        optimizer_params={'learning_rate':0.5, 'momentum': 0.9,'wd':0.0001 },\n",
    "        num_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_score=[]\n",
    "val_score=[]\n",
    "epoch=[]\n",
    "for i in range(0,100):\n",
    "    \n",
    "    sym, arg_params, aux_params = \\\n",
    "            mx.model.load_checkpoint(model_prefix, i+1)\n",
    "        \n",
    "    mod.set_params(arg_params, aux_params)\n",
    "    res_train = mod.score(train_sketches, mx.metric.Accuracy(),num_batch=40)\n",
    "    res_val= mod.score(val_sketches, mx.metric.Accuracy(),num_batch=8)\n",
    "    epoch.append(i+1)\n",
    "    for name, value in res_train:\n",
    "        print 'Epoch[%d] Training-%s=%f' %(i+1, name, value)\n",
    "        train_score.append(value)\n",
    "    for name, value in res_val:\n",
    "        print 'Epoch[%d] Validation-%s=%f' %(i+1, name, value)\n",
    "        val_score.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logfile_url= '%s-eval-metric-log-accuracy.txt' % (model_prefix)\n",
    "print 'saving logfiles  at %s' % (logfile_url)\n",
    "logfile = open(logfile_url, 'a')\n",
    "for  epoch,train_metric, val_metric in zip(epoch,train_score,val_score):\n",
    "    #logfile.write(\"%s\\n\" % item)\n",
    "\n",
    "\n",
    "    logfile.write(str(epoch)+\"\\t\"+str(train_metric)+\"\\t\"+ str(val_metric)+\"\\n\")\n",
    "logfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
